{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397dbcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm  # allows you to output a smart progress bar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1595d",
   "metadata": {},
   "source": [
    "# downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3fe0973",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "74.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "92.9%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FashionMNIST\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "119.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FashionMNIST\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to FashionMNIST\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "root = 'FashionMNIST'\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=root,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=root,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e20384e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a83e9bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca9f51",
   "metadata": {},
   "source": [
    "# sample view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "668b0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0:'T-shirt/top',\n",
    "    1:'Trouser',\n",
    "    2:'Pullover',\n",
    "    3:'Dress',\n",
    "    4:'Coat',\n",
    "    5:'Sandal',\n",
    "    6:'Shirt',\n",
    "    7:'Sneaker',\n",
    "    8:'Bag',\n",
    "    9:'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c610db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_sample_img(data, index, label_map):\n",
    "    plt.imshow(data.data[index], cmap='gray')\n",
    "    plt.title(f'Data Label: {label_map[data.targets[index].item()]}')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71fddbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "view_sample_img(train_data, index=7, label_map=label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbec631",
   "metadata": {},
   "source": [
    "## Creating Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33237a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    )\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8becd2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for data, label in test_data_loader:\n",
    "    print(data.shape)\n",
    "    print(label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61a169ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d69e45ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e50d34",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88e0d2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d37efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_, out_):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv_pool_01 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_,out_channels=8,kernel_size=5,stride=1,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv_pool_02 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=8,out_channels=16,kernel_size=5,stride=1,padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.FC_01 = nn.Linear(in_features=16*4*4, out_features=128)\n",
    "        self.FC_02 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.FC_03 = nn.Linear(in_features=64, out_features=out_)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv_pool_01(x)\n",
    "        x = self.conv_pool_02(x)\n",
    "        x = self.Flatten(x)\n",
    "        x = self.FC_01(x)\n",
    "        x = self.FC_02(x)\n",
    "        x = self.FC_03(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22089f2",
   "metadata": {},
   "source": [
    "in convolutional 2d NN (this part is comes in ANN/CNN, not covered yet)\n",
    "- images are 28X28 pixel as input\n",
    "- h1 = w1 = 28\n",
    "- input channel = 1\n",
    "- output channel = 8\n",
    "- kernal size = 5 (5X5)\n",
    "- padding = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90d21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def output_size(input_size, kernal_size, stride, padding):\n",
    "    '''\n",
    "    \n",
    "    Input size = Image pixel size, input height for output height\n",
    "                 input width for output width\n",
    "    '''\n",
    "    result = math.floor(((input_size-kernal_size+2*padding)/stride)+1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e4f85f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size(16,2,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3c74d016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "input_size = 28  # input image pixel height/width\n",
    "kernal_size = 5\n",
    "stride = 1  # no of steps\n",
    "padding = 0\n",
    "op_size = output_size(input_size,kernal_size,stride,padding)\n",
    "# for 28X28 pixel size image output size is 24X24\n",
    "print(op_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81206892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv_pool_01): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_pool_02): Sequential(\n",
       "    (0): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (FC_01): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (FC_02): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (FC_03): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN(1, 10)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e5378",
   "metadata": {},
   "source": [
    "## Count No. of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1dd70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_para(model):  \n",
    "    model_params = {'Modules': [], 'Parameters': []}  # creating dictionary to make pandas df\n",
    "    total = 0  # initially no. of params \n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:  # if parameter not requires gradiant means it's untrainable\n",
    "            continue  # so we'll just skip it\n",
    "        param = parameter.numel()\n",
    "        model_params['Modules'].append(name)\n",
    "        model_params['Parameters'].append(param)\n",
    "        total += param\n",
    "    df = pd.DataFrame(model_params)\n",
    "    df = df.style.set_caption(f'Total trainable parameters is: {total}')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "592dee8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_cc87b\">\n",
       "  <caption>Total trainable parameters is: 45226</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cc87b_level0_col0\" class=\"col_heading level0 col0\" >Modules</th>\n",
       "      <th id=\"T_cc87b_level0_col1\" class=\"col_heading level0 col1\" >Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cc87b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cc87b_row0_col0\" class=\"data row0 col0\" >conv_pool_01.0.weight</td>\n",
       "      <td id=\"T_cc87b_row0_col1\" class=\"data row0 col1\" >200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cc87b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cc87b_row1_col0\" class=\"data row1 col0\" >conv_pool_01.0.bias</td>\n",
       "      <td id=\"T_cc87b_row1_col1\" class=\"data row1 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cc87b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cc87b_row2_col0\" class=\"data row2 col0\" >conv_pool_02.0.weight</td>\n",
       "      <td id=\"T_cc87b_row2_col1\" class=\"data row2 col1\" >3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cc87b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_cc87b_row3_col0\" class=\"data row3 col0\" >conv_pool_02.0.bias</td>\n",
       "      <td id=\"T_cc87b_row3_col1\" class=\"data row3 col1\" >16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cc87b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_cc87b_row4_col0\" class=\"data row4 col0\" >FC_01.weight</td>\n",
       "      <td id=\"T_cc87b_row4_col1\" class=\"data row4 col1\" >32768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cc87b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_cc87b_row5_col0\" class=\"data row5 col0\" >FC_01.bias</td>\n",
       "      <td id=\"T_cc87b_row5_col1\" class=\"data row5 col1\" >128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cc87b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_cc87b_row6_col0\" class=\"data row6 col0\" >FC_02.weight</td>\n",
       "      <td id=\"T_cc87b_row6_col1\" class=\"data row6 col1\" >8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cc87b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_cc87b_row7_col0\" class=\"data row7 col0\" >FC_02.bias</td>\n",
       "      <td id=\"T_cc87b_row7_col1\" class=\"data row7 col1\" >64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cc87b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_cc87b_row8_col0\" class=\"data row8 col0\" >FC_03.weight</td>\n",
       "      <td id=\"T_cc87b_row8_col1\" class=\"data row8 col1\" >640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cc87b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_cc87b_row9_col0\" class=\"data row9 col0\" >FC_03.bias</td>\n",
       "      <td id=\"T_cc87b_row9_col1\" class=\"data row9 col1\" >10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x12b9cf57fa0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_para(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b77d97",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "29aee747",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "n_epoch = 10\n",
    "n_steps = len(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a112bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148a47e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    with tqdm(train_data_loader) as tqdm_epoch:\n",
    "# here at this moment we decided to go learn deep learning ANN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "50b2427cf95ee5a80904b8037d2543a24e2b8f0fe02719f7c820e36c5efab1b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
